{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7b977c-21ef-4fd5-aa5b-a015a204431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16808\\342940549.py:59: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  orders = orders.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16808\\342940549.py:60: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  returns = returns.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16808\\342940549.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  users   = users.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV files saved\n",
      "Data successfully imported to SQLite database: C:\\Users\\user\\Desktop\\superstore_analyse\\sales_dashboard.db\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Superstore Data Preprocessing Script\n",
    "------------------------------------\n",
    "Purpose:\n",
    "1. Read SuperStore Excel data (Orders, Returns, Users)\n",
    "2. Clean and normalize data\n",
    "3. Save cleaned datasets to CSV\n",
    "4. Import cleaned data into SQLite database with indexes\n",
    "\n",
    "Author: [POUYA BATHAEI POURMAND]\n",
    "Date: [2025-8-15]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Paths & File Names\n",
    "# -------------------------------\n",
    "# Define the directory where the data file is stored\n",
    "DATA_DIR = Path(r\"C:\\Users\\user\\Desktop\\superstore_analyse\")\n",
    "# Define the Excel file path\n",
    "EXCEL_FILE = DATA_DIR / \"SuperStoreUS-2015.xlsx\"\n",
    "# Define the SQLite database file path\n",
    "DB_FILE = DATA_DIR / \"sales_dashboard.db\"\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Read Data from Excel\n",
    "# -------------------------------\n",
    "# Load each sheet from the Excel file into separate DataFrames\n",
    "orders = pd.read_excel(EXCEL_FILE, sheet_name=\"Orders\", engine=\"openpyxl\")\n",
    "returns = pd.read_excel(EXCEL_FILE, sheet_name=\"Returns\", engine=\"openpyxl\")\n",
    "users = pd.read_excel(EXCEL_FILE, sheet_name=\"Users\", engine=\"openpyxl\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Normalize Column Names\n",
    "# -------------------------------\n",
    "# Function to clean column names: lowercase, replace spaces/special chars with underscores\n",
    "def normalize_cols(df):\n",
    "    cols = (df.columns\n",
    "              .str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace('[^0-9a-zA-Z]+', '_', regex=True)\n",
    "              .str.replace('_+', '_', regex=True)\n",
    "              .str.strip('_'))\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "orders = normalize_cols(orders)\n",
    "returns = normalize_cols(returns)\n",
    "users   = normalize_cols(users)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Clean Data\n",
    "# -------------------------------\n",
    "# Remove leading/trailing spaces from string values\n",
    "orders = orders.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "returns = returns.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "users   = users.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Fix inconsistent order priority values\n",
    "if 'order_priority' in orders.columns:\n",
    "    orders['order_priority'] = orders['order_priority'].replace({'Not Specified': 'Low'})\n",
    "\n",
    "# Drop rows with missing essential values in Orders\n",
    "orders = orders.dropna(subset=['sales', 'profit', 'order_date'])\n",
    "\n",
    "# Ensure numeric columns have correct type\n",
    "numeric_cols = ['discount', 'unit_price', 'shipping_cost', 'profit', 'quantity_ordered_new', 'sales']\n",
    "for col in numeric_cols:\n",
    "    if col in orders.columns:\n",
    "        orders[col] = pd.to_numeric(orders[col], errors='coerce')\n",
    "\n",
    "# Add calculated column: total_sales = unit_price * quantity_ordered_new\n",
    "if all(col in orders.columns for col in ['unit_price', 'quantity_ordered_new']):\n",
    "    orders['total_sales'] = orders['unit_price'] * orders['quantity_ordered_new']\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Save Cleaned CSVs\n",
    "# -------------------------------\n",
    "# Save cleaned data into CSV files\n",
    "orders_file  = r\"C:\\Users\\user\\Desktop\\superstore_analyse\\orders_clean.csv\"\n",
    "returns_file = r\"C:\\Users\\user\\Desktop\\superstore_analyse\\returns_clean.csv\"\n",
    "users_file   = r\"C:\\Users\\user\\Desktop\\superstore_analyse\\users_clean.csv\"\n",
    "\n",
    "orders.to_csv(orders_file, index=False)\n",
    "returns.to_csv(returns_file, index=False)\n",
    "users.to_csv(users_file, index=False)\n",
    "\n",
    "print(\"Cleaned CSV files saved\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Import to SQLite Database\n",
    "# -------------------------------\n",
    "# Create SQLite engine (connection)\n",
    "engine = create_engine(f\"sqlite:///{DB_FILE}\", echo=False)\n",
    "\n",
    "# Load DataFrames into SQLite database tables\n",
    "orders.to_sql('orders', engine, if_exists='replace', index=False)\n",
    "returns.to_sql('returns', engine, if_exists='replace', index=False)\n",
    "users.to_sql('users', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Create indexes for better query performance\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text('CREATE INDEX IF NOT EXISTS idx_orders_orderid ON orders (order_id);'))\n",
    "    conn.execute(text('CREATE INDEX IF NOT EXISTS idx_returns_orderid ON returns (order_id);'))\n",
    "    conn.execute(text('CREATE INDEX IF NOT EXISTS idx_orders_customer ON orders (customer_id);'))\n",
    "    conn.commit()\n",
    "\n",
    "print(f\"Data successfully imported to SQLite database: {DB_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc841eee-07b1-4bb5-9e9f-78299e8a405a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
